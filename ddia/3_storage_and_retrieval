Got it ✅ You want me to explain this passage from Chapter 3: Storage and Retrieval (from Designing Data-Intensive Applications) without missing any point, and with the same headings as in the text. I’ll break it down step by step with clear explanations.

CHAPTER 3
Storage and Retrieval

At the most basic level, a database must do two things:

Store data when you provide it.

Retrieve data when you request it later.

In Chapter 2, we looked at data models and query languages (how applications talk to databases).
In this chapter, the focus shifts to how the database itself stores and retrieves data internally.

Why should you care as an application developer?

You may not build your own storage engine, but you need to choose one that fits your application.

To optimize and tune performance, you need a basic understanding of how a storage engine works.

There are two broad workload categories:

Transactional workloads (OLTP) → optimized for lots of small reads/writes.

Analytical workloads (OLAP) → optimized for large scans and aggregations.

This distinction will be explored later:

“Transaction Processing or Analytics?” (p. 90)

“Column-Oriented Storage” (p. 95)

But first, the chapter discusses two families of storage engines used in relational and many NoSQL databases:

Log-structured storage engines

Page-oriented storage engines (e.g., B-trees)

Data Structures That Power Your Database

To understand storage engines, let’s start with a toy example:

Example: A Bash-based Key-Value Store
db_set () {
  echo "$1,$2" >> database
}

db_get () {
  grep "^$1," database | sed -e "s/^$1,//" | tail -n 1
}


db_set key value → Stores the key-value pair in the database file.

db_get key → Finds and returns the most recent value for a key.

Usage:
$ db_set 123456 '{"name":"London","attractions":["Big Ben","London Eye"]}'
$ db_set 42 '{"name":"San Francisco","attractions":["Golden Gate Bridge"]}'
$ db_get 42
{"name":"San Francisco","attractions":["Golden Gate Bridge"]}


The database file looks like this (CSV-like format):

123456,{"name":"London","attractions":["Big Ben","London Eye"]}
42,{"name":"San Francisco","attractions":["Golden Gate Bridge"]}

How It Works

Every call to db_set → Appends to the end of the file.

Updates don’t overwrite old values → Instead, the latest occurrence of a key is considered the valid one.

Example (updating San Francisco attractions):

$ db_set 42 '{"name":"San Francisco","attractions":["Exploratorium"]}'
$ db_get 42
{"name":"San Francisco","attractions":["Exploratorium"]}


Now the file contains:

123456,{"name":"London","attractions":["Big Ben","London Eye"]}
42,{"name":"San Francisco","attractions":["Golden Gate Bridge"]}
42,{"name":"San Francisco","attractions":["Exploratorium"]}

Performance of db_set

Good performance → Because appending to a file is efficient.

Many real databases also use this idea: logs (append-only data files).

Databases need extra features beyond this simple script:

Concurrency control (multiple users writing/reading at once).

Space management (so the file doesn’t grow forever).

Error handling (partial writes, crashes, corruption).

But the append-only log principle is still widely used.

What is a Log?

Not the same as application logs (human-readable text about events).

In databases → A log = append-only sequence of records.

It may be binary and only meant for machines to read.

Performance of db_get

Very inefficient for large files.

Each lookup requires scanning the entire file → O(n) complexity.

If records double, lookup time also doubles.

Clearly not scalable.

Solution: Indexes

To make lookups efficient, we need an index.

Index = an extra data structure that stores metadata to speed up searches.

Works like a signpost that tells you where to find data quickly.

If you need different search options (e.g., by name, by ID), you may need multiple indexes.

Index Trade-offs

An index doesn’t change the database contents, only query performance.

Indexes speed up reads but slow down writes:

Every new write must also update the index.

In contrast, appending directly to a file (like our db_set) is the fastest possible write.

Therefore:

Databases don’t index everything automatically.

Developers/DBAs must choose indexes manually → based on query patterns.

Goal: Balance read performance with write overhead.

✅ Summary of Key Points:

Databases must store and retrieve data.

Workloads differ: transactional vs analytical.

Two main storage engines: log-structured and B-tree/page-oriented.

Example Bash DB shows how append-only logs work.

db_set is efficient (append-only), db_get is slow (O(n) lookup).

Solution → Indexes.

Trade-off: Indexes speed up reads but slow down writes.


