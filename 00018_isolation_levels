Subtasks of writing:

example of update steps:
read
modify
write

In a transaction , there can be multiple reads and writes.
Transaction can be called a step by step process of reads writes deletes updtes like  CRUD


In the context of database management systems, isolation levels define the degree to which the operations in one transaction are isolated from those in other concurrent transactions. The goal is to balance data consistency with performance and concurrency.


üîí ACID "I" ‚Äì Isolation
Isolation is the "I" in ACID, and different isolation levels control how/when the changes made by one transaction become visible to others.

durability - disk persistence and WAL and master slave (in case of master failure , slave is promoted to master)
snapshot isolation

üîÑ Read Phenomena
Isolation levels are defined based on which of these undesirable phenomena are allowed:

Phenomenon	

| Phenomenon                          | Description                                                                                            |
| ---------------------------------   | ------------------------------------------------------------------------------------------------------ |
| **Dirty Read**                      | A transaction reads uncommitted changes made by another transaction.                                   |
| **Non-Repeatable Read/ Read Skew**  | A row read twice within a transaction gives different results because another transaction modified it. |
| **Phantom Read**                    | New rows added by another transaction are visible in a repeated query.                                 |


üß± ANSI SQL Isolation Levels

| Level                               | Dirty Read  | Non-Repeatable Read | Phantom Read | Notes                                              |
| ----------------------------        | ----------- | ------------------- | ------------ | -------------------------------------------------- |
| **Read Uncommitted**                | ‚úÖ Allowed   | ‚úÖ Allowed           | ‚úÖ Allowed    | Fastest but unsafe                                 |
| **Read Committed**                  | ‚ùå Prevented | ‚úÖ Allowed           | ‚úÖ Allowed    | Default in many systems (e.g., SQL Server, Oracle) |
| **Repeatable Read/ Snapshot **      | ‚ùå Prevented | ‚ùå Prevented         | ‚úÖ Allowed    | Default in MySQL InnoDB                            |
| **Serializable**                    | ‚ùå Prevented | ‚ùå Prevented         | ‚ùå Prevented  | Most strict and safest, but slowest                |


üì¶ Summary Table

| Isolation Level  | Prevents Dirty Reads | Prevents Non-Repeatable Reads | Prevents Phantom Reads |
| ---------------- | -------------------- | ----------------------------- | ---------------------- |
| Read Uncommitted | ‚ùå                    | ‚ùå                             | ‚ùå                      |
| Read Committed   | ‚úÖ                    | ‚ùå                             | ‚ùå                      |
| Repeatable Read  | ‚úÖ                    | ‚úÖ                             | ‚ùå                      |
| Serializable     | ‚úÖ                    | ‚úÖ                             | ‚úÖ                      |


üõ† DBMS-Specific Notes
MySQL (InnoDB): Default is REPEATABLE READ. Phantom reads are avoided using Next-Key Locks.

PostgreSQL: Uses MVCC (Multiversion Concurrency Control), making READ COMMITTED safe without blocking.

SQL Server: Defaults to READ COMMITTED; also supports Snapshot Isolation.

Oracle: Uses READ COMMITTED by default with non-blocking reads using versioning (similar to MVCC).


Snapshot Isolation:

Snapshot Isolation (SI) is a database isolation level that provides consistent reads without blocking writers,
and vice versa, using multi-version concurrency control (MVCC).

üî∑ What is Snapshot Isolation?
Snapshot Isolation ensures that:

Each transaction reads data from a consistent snapshot (i.e., the state of the database when the transaction started).

Changes made by concurrent uncommitted transactions are not visible.

No read locks are acquired, so reads don't block writes and vice versa.

Write-write conflicts are detected at commit time.



üîß Example
Assume two transactions run concurrently:

T1:

START TRANSACTION;
SELECT balance FROM account WHERE id = 1; -- reads balance = 100
-- some processing...
UPDATE account SET balance = 90 WHERE id = 1;
COMMIT;


T2:

START TRANSACTION;
SELECT balance FROM account WHERE id = 1; -- reads balance = 100
-- some processing...
UPDATE account SET balance = 80 WHERE id = 1;
COMMIT; -- ‚ùå Conflict! Write-write conflict with T1


üß† Key Properties

| Property             | Supported by SI  |
| -------------------- | ---------------- |
| Consistent read view | ‚úÖ Yes            |
| Dirty reads          | ‚ùå No             |
| Non-repeatable reads | ‚ùå No             |
| Phantom reads        | ‚ùå No (partially) |
| Write skew anomaly   | ‚ùå May occur      |


Snapshot Isolation is stronger than Read Committed but weaker than Serializable.

‚ö†Ô∏è Write Skew Anomaly Example
Two doctors, D1 and D2, must not go off-call simultaneously:

-- Initial: D1 = on-call, D2 = on-call

T1:                          T2:
SELECT status(D2);          SELECT status(D1);  -- both see "on-call"
UPDATE D1 SET off-call;     UPDATE D2 SET off-call;
COMMIT;                     COMMIT;


‚û°Ô∏è Now both are off-call, violating a constraint, even though they both saw consistent snapshots.

üìå Where It‚Äôs Used
PostgreSQL (REPEATABLE READ implements Snapshot Isolation)

SQL Server (SNAPSHOT isolation level)

Oracle (default uses SI-like mechanism)

MySQL (InnoDB) uses MVCC, similar to SI but defaults to REPEATABLE READ with different semantics



‚úÖ Pros
High performance for read-heavy workloads

No read locks: better concurrency

No dirty reads or non-repeatable reads
‚ùå Cons
Doesn‚Äôt prevent write skew anomalies

More memory/IO overhead (stores older row versions)

Conflict detection at commit time may lead to retries

üÜö Comparison with Other Isolation Levels

| Isolation Level  | Prevents Dirty Reads | Non-repeatable Reads | Phantom Reads | Write Skew |
| ---------------- | -------------------- | -------------------- | ------------- | ---------- |
| Read Uncommitted | ‚ùå                    | ‚ùå                    | ‚ùå             | ‚ùå          |
| Read Committed   | ‚úÖ                    | ‚ùå                    | ‚ùå             | ‚ùå          |
| **Snapshot**     | ‚úÖ                    | ‚úÖ                    | ‚úÖ             | ‚ùå          |
| Serializable     | ‚úÖ                    | ‚úÖ                    | ‚úÖ             | ‚úÖ          |


Would you like:

A diagram of MVCC in Snapshot Isolation?

A Java/JDBC example using Snapshot Isolation?

A comparison with Serializable isolation with scenarios?



Snapshot Isolation (SI) and Serializable Isolation are two high-level database isolation strategies that aim to 
maintain data consistency during concurrent transactions. While both prevent common anomalies like dirty reads and non-repeatable reads,
they differ in implementation, performance, and the types of anomalies they can prevent.

üîç Snapshot Isolation (SI)
Mechanism: Utilizes Multi-Version Concurrency Control (MVCC) to provide each transaction with a consistent snapshot
of the database at the start of the transaction.

Key Characteristics:

Read Consistency: Transactions read data as it existed at the start time, ignoring concurrent modifications.

No Read Locks: Readers don't block writers and vice versa, enhancing concurrency.

Write Conflicts: If two transactions modify the same data, the one that commits second will fail.
Wikipedia

Pros:

High concurrency due to non-blocking reads.

Avoids common anomalies like dirty reads and non-repeatable reads.

Cons:

Susceptible to write skew anomalies, where concurrent transactions read overlapping data and make disjoint updates, 
leading to inconsistent states. 
TECHCOMMUNITY.MICROSOFT.COM
+2
Wikipedia
+2
GeeksforGeeks
+2

üîí Serializable Isolation
Mechanism: Ensures that transactions execute in a manner equivalent to some serial (one after another) order, typically using locks.
Wikipedia
+2
Repost
+2
IT trip
+2

Key Characteristics:

Strict Consistency: Prevents all concurrency anomalies, including phantom reads and write skew.

Locking: Employs read and write locks, holding them until the transaction completes.

Reduced Concurrency: Transactions may block each other, leading to potential deadlocks.
Wikipedia
GeeksforGeeks
+2
Wikipedia
+2
MSSQLTips
+2

Pros:

Provides the highest level of isolation and consistency.

Suitable for applications requiring strict data integrity.

Cons:

Lower concurrency due to blocking.

Potential for deadlocks and increased resource contention.
TECHCOMMUNITY.MICROSOFT.COM
+2
Repost
+2
Stack Overflow
+2

üÜö Comparison Table

| Feature                 | Snapshot Isolation (SI)                                      | Serializable Isolation                                  |                                                                                         |
| ----------------------- | ------------------------------------------------------------ | ------------------------------------------------------- | --------------------------------------------------------------------------------------- |
| **Concurrency Control** | Optimistic (MVCC)                                            | Pessimistic (Locking)                                   |                                                                                         |
| **Read Behavior**       | Reads from a consistent snapshot                             | Reads reflect the latest committed data                 |                                                                                         |
| **Write Conflicts**     | Detected at commit time; one transaction aborts              | Prevented via locks; transactions may block each other  |                                                                                         |
| **Anomalies Prevented** | Dirty reads, non-repeatable reads, phantom reads             | All, including write skew                               |                                                                                         |
| **Performance**         | High concurrency, better performance                         | Lower concurrency, potential for blocking               |                                                                                         |
| **Use Cases**           | Read-heavy workloads, applications tolerating some anomalies | Applications requiring strict consistency and integrity | ([Michael J. Swart \| Database Whisperer][1], [GeeksforGeeks][2], [Microsoft Learn][3]) |

[1]: https://michaeljswart.com/2010/04/transaction-phenomena-part-4-serializable-vs-snapshot/?utm_source=chatgpt.com "Transaction Phenomena ‚Äì Part 4: Serializable vs. Snapshot"
[2]: https://www.geeksforgeeks.org/snapshot-isolation-vs-serializable/?utm_source=chatgpt.com "Snapshot Isolation vs Serializable - GeeksforGeeks"
[3]: https://learn.microsoft.com/en-us/dotnet/framework/data/adonet/sql/snapshot-isolation-in-sql-server?utm_source=chatgpt.com "Snapshot Isolation in SQL Server - ADO.NET | Microsoft Learn"


üìù Example Scenario: Write Skew Anomaly
Consider a hospital system where two doctors, Dr. A and Dr. B, must not be off-duty simultaneously. The rule is enforced by ensuring at least one doctor is on duty at any time.

Under Snapshot Isolation:

Dr. A checks that Dr. B is on duty and decides to go off-duty.

Simultaneously, Dr. B checks that Dr. A is on duty and decides to go off-duty.

Both transactions commit, resulting in both doctors being off-duty, violating the constraint.

Under Serializable Isolation:

The system would prevent this anomaly by ensuring that one transaction sees the other's update, thus maintaining the constraint.

üèÅ Conclusion
While both Snapshot and Serializable isolation levels aim to maintain data consistency, they cater to different needs:

Snapshot Isolation is suitable for applications that prioritize performance and can tolerate certain anomalies.

Serializable Isolation is ideal for applications where strict data integrity is paramount, despite potential performance trade-offs.

Understanding the specific requirements and constraints of your application will guide the choice between these isolation levels.




-----------





https://www.geeksforgeeks.org/dbms/what-is-multi-version-concurrency-control-mvcc-in-dbms/


What is Multi-Version Concurrency Control (MVCC) in DBMS?
Last Updated : 21 Mar, 2024
Multi-Version Concurrency Control (MVCC) is a database optimization method, that makes redundant copies of records to allow for safe concurrent reading and updating of data. DBMS reads and writes are not blocked by one another while using MVCC. A technique called concurrency control keeps concurrent processes running to avoid read/write conflicts or other irregularities in a database.

Whenever it has to be updated rather than replacing the old one with the new information an MVCC database generates a newer version of the data item.

What is Multi-Version Concurrency Control (MVCC) in DBMS?
Multi-Version Concurrency Control is a technology, utilized to enhance databases by resolving concurrency problems and also data locking by preserving older database versions. When many tasks attempt to update the same piece of data simultaneously, MVCC causes a conflict and necessitates a retry from one or more of the processes.

Types of Multi-Version Concurrency Control (MVCC) in DBMS
Below are some types of Multi-Version Concurrency Control (MVCC) in DBMS

Timestamp-based MVCC: The data visibility to transactions is defined by the unique timestamp assigned to each transaction that creates a new version of a record.
Snapshot-based MVCC: This utilizes the database snapshot that is created at the beginning of a transaction to supply the information that is needed for the transaction.
History-based MVCC: This Keeps track of every modification made to a record, making transaction rollbacks simple.
Hybrid MVCC: This coordinates data flexibility and performance by combining two or more MVCC approaches.
How Does Multi-Version Concurrency Control (MVCC) in DBMS Works?
In the database, every tuple has a version number. The tuple with the greatest version number can have a read operation done on it simultaneously.
Only a copy of the record may be used for writing operations.
While the copy is being updated concurrently, the user may still view the previous version.
The version number is increased upon successful completion of the writing process.
The upgraded version is now used for every new record operation and every time there is an update, this cycle is repeated.
Implementation of Multi-Version Concurrency Control (MVCC) in DBMS
MVCC operates time stamps (TS) and increases transaction IDs to assure transactional consistency. MVCC manage many copies of the object, ensuring that a transaction (T) never has to wait to read a database object (P).
A specific transaction Ti can read the most recent version of the object, which comes before the transaction's Read Timestamp RTS(Ti) since each version of object P contains both a Read Timestamp and a Write Timestamp.
If there are other pending transactions to the same object that have an earlier Read Timestamp (RTS), then a Write cannot be completed.
You cannot finish your checkout transaction until the person in front of you has finished theirs, much as when you are waiting in a queue at the shop.
To reiterate, each object (P) has a Timestamp (TS). Should transaction Ti attempt to Write to an object and its Timestamp (TS) exceeds the object's current Read Timestamp, 

TS(Ti)<RTS(P), the transaction will be cancelled and retried.
Ti makes a new copy of object P and sets its read/write timestamp (TS) to the transaction timestamp 
(TS‚ÜûTS(Ti)).
Advantages of Multi-Version Concurrency Control (MVCC) in DBMS
Below are some advantages of Multi-Version Concurrency Control in DBMS

The reduced read-and-write necessity for database locks: The database can support many read-and-write transactions without locking the entire system thanks to MVCC.
Increased Concurrency: This Enables several users to use the system at once.
Minimize read operation delays: By enabling concurrent read operations, MVCC helps to cut down on read times for data.
Accuracy and consistency: Preserves data integrity over several concurrent transactions.
Disadvantages of Multi-Version Concurrency Control (MVCC) in DBMS
Below are some disadvantages of Multi-Version Concurrency Control in DBMS

Overhead: Keeping track of many data versions might result in overhead.
Garbage collecting: To get rid of outdated data versions, MVCC needs effective garbage collecting systems.
Increase the size of the database: Expand the capacity of the database since MVCC generates numerous copies of the records and/or tuples.
Complexity: Compared to more straightforward locking systems, MVCC usage might be more difficult.
Conclusion
In conclusion, Multiversion Concurrency Control (MVCC) in DBMS is a database optimization method, that makes redundant copies of records to allow for safe concurrent reading and updating of data. When many tasks attempt to update the same piece of data simultaneously, MVCC causes a conflict and necessitates a retry from one or more of the processes.


---------


Nice one üëç ‚Äî Copy-on-Write (CoW) is a classic optimization technique used in databases, file systems, and programming languages.

üîë Definition

Copy-on-Write (CoW) means:
üëâ Instead of making an immediate deep copy of data, multiple consumers share the same copy until someone tries to modify it. At that moment, a private copy is made for the writer.

So:

Read = shared (no duplication).

Write = copy (only then is a new version created).

‚öôÔ∏è How It Works

Initially, data is shared between processes/threads.

If no one modifies ‚Üí no copies are made.

If one modifies ‚Üí system makes a private copy for the writer (others still see the original).
